{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d41d1b70962b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from ns3gym import ns3env\n",
    "\n",
    "env = gym.make('ns3-v0')\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space\n",
    "print(\"Observation space: \", ob_space,  ob_space.dtype)\n",
    "print(\"Action space: \", ac_space, ac_space.n)\n",
    "\n",
    "s_size = ob_space.shape[0]\n",
    "a_size = ac_space.n\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(s_size, input_shape=(s_size,), activation='relu'))\n",
    "model.add(keras.layers.Dense(a_size, activation='softmax'))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "total_episodes = 50\n",
    "max_env_steps = 100\n",
    "env._max_episode_steps = max_env_steps\n",
    "\n",
    "epsilon = 0.8               # exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 1.0\n",
    "\n",
    "time_history = []\n",
    "rew_history = []\n",
    "\n",
    "for e in range(total_episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, s_size])\n",
    "    rewardsum = 0\n",
    "    for time in range(max_env_steps):\n",
    "\n",
    "        # Choose action\n",
    "        if np.random.rand(1) < epsilon:\n",
    "            action = np.random.randint(a_size)\n",
    "        else:\n",
    "            action = time % 4\n",
    "\n",
    "        # Step\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        print(\"next_state: {}, action: {}, reward: {}, done: {}\"\n",
    "              .format(next_state, action, reward, done))\n",
    "\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, time: {}, rew: {}, eps: {:.2}\"\n",
    "                  .format(e, total_episodes, time, rewardsum, epsilon))\n",
    "            break\n",
    "\n",
    "        next_state = np.reshape(next_state, [1, s_size])\n",
    "\n",
    "        # Train\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = (reward + 0.95 * np.amax(model.predict(next_state)[0]))\n",
    "\n",
    "        target_f = model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "        state = next_state\n",
    "        rewardsum += reward\n",
    "        if epsilon > epsilon_min: epsilon *= epsilon_decay\n",
    "        \n",
    "    time_history.append(time)\n",
    "    rew_history.append(rewardsum)\n",
    "\n",
    "#for n in range(2 ** s_size):\n",
    "#    state = [n >> i & 1 for i in range(0, 2)]\n",
    "#    state = np.reshape(state, [1, s_size])\n",
    "#    print(\"state \" + str(state) \n",
    "#        + \" -> prediction \" + str(model.predict(state)[0])\n",
    "#        )\n",
    "\n",
    "#print(model.get_config())\n",
    "#print(model.to_json())\n",
    "#print(model.get_weights())\n",
    "\n",
    "print(\"Plot Learning Performance\")\n",
    "# mpl.rcdefaults()\n",
    "# mpl.rcParams.update({'font.size': 16})\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10,4))\n",
    "# plt.grid(True, linestyle='--')\n",
    "# plt.title('Learning Performance')\n",
    "# plt.plot(range(len(time_history)), time_history, label='Steps', marker=\"^\", linestyle=\":\")#, color='red')\n",
    "# plt.plot(range(len(rew_history)), rew_history, label='Reward', marker=\"\", linestyle=\"-\")#, color='k')\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Time')\n",
    "# plt.legend(prop={'size': 12})\n",
    "\n",
    "# plt.savefig('learning.pdf', bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}